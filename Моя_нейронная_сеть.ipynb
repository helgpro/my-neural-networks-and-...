{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-4187d10a64fe>, line 68)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-4187d10a64fe>\"\u001b[1;36m, line \u001b[1;32m68\u001b[0m\n\u001b[1;33m    self.wih += self.lr * np.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), np.transpose(inputs))\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.special\n",
    "# Создания класа нейронки\n",
    "class neuralNetwork:\n",
    " \n",
    "    def __init__(self, inputnods, hiddennods, outputnodes,learningrate):\n",
    "        self.inods = inputnods\n",
    "        self.hidnods = hiddennods\n",
    "        self.outnods = outputnodes\n",
    "  #                                  метод int как конструктор создаем переменные входныхб скрытых, выходных, и \n",
    "\n",
    "        self.lr = learningrate\n",
    "  #                                  скорости обучения\n",
    "    \n",
    "        # Матрицы весовых коэффициентов связей wih и who.\n",
    "        # Весовые коэффициенты связей между узлом i и узлом j\n",
    "        # следующего слоя обозначены как w__i:\n",
    "        # wll w21\n",
    "        # wl2 w22 и т.д.\n",
    "\n",
    "        self.wi = (np.random.rand(self.hidnods,self.inods)-0.5)\n",
    "        self.wo = (np.random.rand(self.outnods,self.hidnods)-0.5)\n",
    "        self.wih = np.random.normal(0.0, pow(self.hidnods, -0.5),(self.hidnods,self.inods)) #pow(3**-0.5) оно будет в self.hideons\n",
    "        self.who = np.random.normal(0.0, pow(self.outnods, -0.5),(self.outnods, self.hidnods))# это 3 на 3\n",
    "        # 0.0 это центр нормального распределения\n",
    "        # pow возводит количество узлов в степень -0.5 так считается стандартное отклонение по количеству узлов\n",
    "        # array([-1.24562004,  0.40499394, -0.42867687])\n",
    "        \n",
    "        # использование сигмоиды в качестве функции активации\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        pass\n",
    "    \n",
    "    def train(self, inputs_list, targets_list):\n",
    "        iput_list += [1]\n",
    "        # преоброзование входных значений в 2D масси\n",
    "        # преобразование списка входных значений\n",
    "        # в двухмерный массив\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        targets = np.array(targets_list, ndmin=2).T\n",
    "        \n",
    "       # рассчитать входящие сигналы для скрытого слоя\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "       # рассчитать исходящие сигналы для скрытого слоя\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        hidden_result = np.dot(self.wih, inputs)\n",
    "        \n",
    "        # рассчитать входящие сигналы для выходного слоя \n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        # рассчитать исходящие сигналы для выходного слоя \n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # ошибки выходного слоя =\n",
    "        # (целевое значение - фактическое значение) те известное значение - то что получилось = ошибка\n",
    "        output_errors = targets - final_outputs\n",
    "        # ошибки скрытого слоя - это ошибки output_errors,\n",
    "        # распределенные пропорционально весовым коэффициентам связей\n",
    "        # и рекомбинированные на скрытых узлах \n",
    "        hidden_errors = np.dot(self.who.T, output_errors) \n",
    "        \n",
    "        ## обновить весовые коэффициенты для связей между\n",
    "        # скрытым и выходным слоями\n",
    "        self.who += self.lr * np.dot((output_errors * final_outputs * (1.0 - final_outputs)), np.transpose(hidden_outputs))\n",
    "        self.who2 += self.lr * np.dot(output_errors * np.transpose(hidden_result)\n",
    "        # нов вес += скорость* скаляр произвед(щштбка* выход значен после сигмы* (1-выход) ) и транспонирует\n",
    "        \n",
    "        # обновить весовые коэффициенты для связей между\n",
    "        # входным и скрытым слоями\n",
    "        self.wih += self.lr * np.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), np.transpose(inputs))\n",
    "        \n",
    "        pass\n",
    "            \n",
    "    \n",
    "    def query(self, input_list):\n",
    "        in_list +=[1]\n",
    "        # преобразовать список входных значений\n",
    "        # в двухмерный массив\n",
    "        inputs = np.array(input_list, ndmin=2).T  \n",
    "        # рассчитать входящие сигналы для скрытого слоя\n",
    "        hidden_inputs = np.dot(self.wih, inputs)   #  Тут скалярное произведение матрицы inputs * веса скрытого слоя\n",
    "        # рассчитать исходящие сигналы для скрытого слоя\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        # рассчитать входящие сигналы для выходного слоя\n",
    "        final_inputs = np.dot(self.who, hidden_outputs) #  Тут скалярное произведение матрицы inputs * веса выходного слоя\n",
    "        # рассчитать исходящие сигналы для выходного слоя\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "\n",
    "        return final_outputs\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ниже пример как создаються случайные веса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5773502691896257\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6fdad23102fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 3 это вход узел сколько скрытых слоев которые возводят в всепень -0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mst\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# и стандартное распроеделение от 0 до 0.57735   - (3,3) масив 3 на 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0min_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "st = pow(3, -0.5) # 3 это вход узел сколько скрытых слоев которые возводят в всепень -0.5\n",
    "print(st)\n",
    "ar = np.random.normal(0.0, st ,(3,3)) # и стандартное распроеделение от 0 до 0.57735   - (3,3) масив 3 на 3 \n",
    "ar\n",
    "in_list = ar\n",
    "its = np.array(in_list, ndmin=2).T\n",
    "print(ar)\n",
    "print(its)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46800679],\n",
       "       [0.48367888],\n",
       "       [0.52638073]])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создае переменые со количеством слоев и\n",
    "innods = 3\n",
    "hinods = 3\n",
    "outnods = 3\n",
    "\n",
    "# Скорость обучения\n",
    "learat =0.3\n",
    "#  объект с положенными данными \n",
    "#myNeural = neuralNetwork(innods, hinods, outnods, learat)\n",
    "n = neuralNetwork(innods, hinods, outnods, learat)\n",
    "\n",
    "\n",
    "#neural.query()\n",
    "#neural.query([1.0, 0.5, -1.5])\n",
    "n.query([1,0.5,-1.5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
